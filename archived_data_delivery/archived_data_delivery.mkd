<!--
Original Author: Peter Venuti
Author Email:    venutip@chop.edu
Last Update:     Peter Venuti
Updated Date:    12/29/2023
Version:         1.0.0
Language:        EN
-->

<!--
[BEGIN] Archived Data Delivery Procedure for Arcus Labs
-->

# Archived Data Delivery Procedure for Arcus Labs

Welcome to the Arcus archived data delivery procedure training course! This course intends to document the high-level standards, dependencies, & procedure involved in requesting & receiving access to archived data within an Arcus lab.

**"Archived Data Delivery"** (sometimes reffered to as "REQ") is an Arcus process in which research data stored in Arcus's archives is made available to a new or existing lab. In most cases, archived datasets are sourced from completed Arcus Labs projects, or are otherwise contributed by researchers & programs partnering with Arcus.

Arcus's Library Science team oversees the curation & organization of contributed data within the archives. When data is contributed, the Library Science team maps the dataset's properties inside its metadata manifest file. Each contribution's metadata manifest is critical for data delivery because it describes the dataset's contents, requirements, & similar properties relevant to delivery.

An archived data delivery request is generally initiated under one of two methods...

<br>

- A new research project is approved for lab deployment which requires one or several patient data cohort/s housed in the Arcus archives.

**OR...**

- An approved request from a study team with an active lab req in which the requested cohort data is stored in the archive.

<br>

**ALL** requests to access archived data **MUST** first be reviewed and approved by an Arcus Privacy analyst. The analyst will ensure that the request does not conflict with protocols, polices, and related legal agreements (i.e: Third Party Agreements, or TPAs, & Data Use Agreements, or DUAs).

Before beginning this course, you should have a basic understanding of Arcus's mission, the Scientific Project (SCIT) lab deployment process, and Arcus terminology.

<br>

*Presented by Arcus Project Management (APM).*
<br>
*Author: Peter Venuti*
<br>
*Last updated 12/29/2023.*

## Terms & Acronyms

The following table provides a comprenhensive list of terms which may be useful for reference throughout this course:

<br>

| Term | Description |
|:-|-|
|**Application Development (AppDev)**| The Arcus functional team responsible for software research, enhcancement, and support. In the context of archived data, an AppDev developer facilitates the execution of delivery for **genomnics** data, as well as any pre-reequisite development necessary to support request fulfillment.|
|**Arcus Data Repository (ADR)**| The name of both the Arcus functional team responsible for delivering clinical data and their supporting database system. In the context of archived data, an ADR analyst primarily facilitates the execution of **non-genomic** data delivery (i.e. archived clinical data). To this end, the ADR analyst also supports the Library Science & AppDev teams as needed with refining the request & preparing for delivery.|
|**Arcus General Support (AG)**| AG is a Jira service project which allows Arcus to recieve, resolve, and track customer requests (PIs/research teams). In the context of archived data, AG is the virtual starting point & documentation for new delivery requests for active research labs.|
|**Arcus Project Management (APM)**|Definition|
|**Library Science (LS)**|Definition|
|**Operational Pipeline**|Definition|
|**Project Owner (PO)**|Definition|
|**Requests (REQ)**|Definition|
|**Scientific Project (SCIT)**|Definition|
|**Subject Matter Expert (SME)**|Definition|


## Archived Data Delivery Procedure

At its highest level, delivering archived data to a lab involves four (4) steps...

1. Assess feasibility & dependencies of the new request.
2. Refine its requirements, prepare execution configuration, & resolve outstanding dependencies.
3. Execute & confirm successful delivery.

<br>

Support from each of the following Arcus functional teams is generally necessary for deliveries of archived data...

- Application Development
- Arcus Data Repository
- Arcus Project Management
- Library Science
- Privacy

<br>

The functional teams utilize the [Requests (REQ)](https://pm.arcus.chop.edu/projects/REQ/queues/custom/311) Jira project to coordinate and track active requests for archived data, where an individual Task object represents a specific lab's request for data. The **Active Archived Data Deliveries** & **Archived Data Delivery (REQ) Sub-Tasks** boards facilitate cross-functional coordination and tracking of active requests.

Generally, Arcus categorizes archived data into one of two types...

1. **Omics Data** – Genetic research data contributed to Arcus by a program/group (such as the Birth Defects repository , BDB, or the Epidemiology & Genomics Research Program, EGRP). Before a contributed dataset is both useable & accessible for research use, the AppDev team must prep the data by processing it through one or several workflow/s. Omics data is archived after processing is finished.
2. **Non-Omics Data** – Non-genetic research data contributed to the Arcus archives. Eseentially any archived data that is not Omics-related, such as previously-active labs or archived clinical data.

<br>

The next three (3) sub-modules will cover each phase of delivering archived data in greater detail. Approximate timelines provided do not take into account atypical complication or abnormalities in the process.

### Phase 1: New Request Assessment

**Overview**

The first phase of the archived data delivery pipeline generally involves documentation, acknowledgedment, and initial assessment of the request.

<br>

**Objectives**

1. Document the request & connect it to relevant/helpful information.
2. Assess the request in core functional areas to determine fulfillment plan and apparent risks, dependencies, & issues.
3. Progress the status of the request to the refinement phase.<br>

<br>

**Roles**

- Arcus Data Repository Analyst
- Application Development Representative
- Arcus Project Manager
- Library Science Representative
- Principal Investigator/Study Team
- Project Owner

<br>

**Environments**

- Jira Projects:

    - [Arcus General Support (AG)](https://pm.arcus.chop.edu/projects/AG/queues/custom/68)
  - [Requests (REQ)](https://pm.arcus.chop.edu/projects/REQ/queues/custom/311)   
  - [Scientific Projects (SCIT)](https://pm.arcus.chop.edu/projects/SCIT/queues/custom/25)

- Jira Boards:

    - [Active Archived Data Deliveries Kanban Board](https://pm.arcus.chop.edu/secure/RapidBoard.jspa?rapidView=137)
   - [Archived Data Delivery (REQ) Sub-Tasks Kanban Board](https://pm.arcus.chop.edu/secure/RapidBoard.jspa?rapidView=154)
 
<br>

**Inputs**

- Archived data delivery request received through either...

    - SCIT lab deployment process
   - Jira Service Desk portal (Arcus General Support)
  
<br>

**Outputs**

- REQ Jira Task

    - (Completed) LS Feasibility Assessment Sub-Task
   - (Completed) AppDev Feasibility Assessment Sub-Task
   - (Completed) Privacy Review Assessment Sub-Task
   - Related tickets linked

<br>

**Procedure**<br>*(Approximate Timeline: 1-3 Working Days)*

1. The request for archived data is received through either of the two (2) input channels. The PO labels the SCIT (or AG) ticket with the label: **archived_data**
2. Jira automations create & link REQ sub-tasks for the LS, AppDev, & Privacy Feasibility Assessments. Sub-tasks are triaged to functional area representatives.
3. LS, AppDev, and Privacy representatives are assigned to assess the request. Each representative assesses the request's feasibility for their respective focus area and records their findings on their respective assessment sub-task.
4. Focus area representatives collaborate to complete all outstanding dependenciesblocking refinement.

### Phase 2: Request Refinement

**Overview**

The second phase of the archived data delivery pipeline generally involves developing dependent solutions, preparing the yml configuration file to execute delivery, and otherwise maturing the request as completelely and thoroughly.

<br>

**Roles**

- Arcus Data Repository Analyst
- Arcus Project Manager
- Application Development Representative
- Library Science Representative
- Principal Investigator/Study Team
- Project Owner

<br>

**Environments**

- Jira Projects:

    - [Arcus General Support (AG)](https://pm.arcus.chop.edu/projects/AG/queues/custom/68)
  - [Requests (REQ)](https://pm.arcus.chop.edu/projects/REQ/queues/custom/311)   
  - [Scientific Projects (SCIT)](https://pm.arcus.chop.edu/projects/SCIT/queues/custom/25)

- Jira Boards:

    - [Active Archived Data Deliveries Kanban Board](https://pm.arcus.chop.edu/secure/RapidBoard.jspa?rapidView=137)
   - [Archived Data Delivery (REQ) Sub-Tasks Kanban Board](https://pm.arcus.chop.edu/secure/RapidBoard.jspa?rapidView=154)

<br>

**Inputs**

- REQ Jira Task

    - (Completed) LS Feasibility Assessment Sub-Task
   - (Completed) AppDev Feasibility Assessment Sub-Task
   - (Completed) Privacy Review Assessment Sub-Task

<br>

**Outputs**

- YML & DIP Files
- Refined REQ Jira Task

   - (Completed) Linked Dependency Tasks/Sub-Tasks
   - (Completed) Participant Feasibility Assessment Sub-Task (when necessary)
   - (Completed) Qualitative Metadata Analysis Sub-Task (when necessary)

<br>

**Procedure**<br>*(Approximate Timeline: 7 – 10 Working Days)*

1. The LS representative & ADR analyst collaboratively assess the request...

    a)  When appropriate, the LS representative performs a participant assessment using the RDS system.
    <br>
    b)  When appropriate, the LS representative performs a qualitative analysis for availble library metadata.
    <br>
    c)  When appliable, the LS representative & ADR analyst performs a Data Expert analysis
    <br>

2. When applicable, Arcus subject matter experts coordinate with customer/s to deteremine feasible paths forward and appropriate alterations.
3. When applicable, the ADR analyst fulfills prerequisite non-archival delivery.
4. When applicable, The AppDev developer completes all required pre-delivery development.
5. The LS representative creates or repurposes an existing YML file & DIP rule configuration.

### Phase 3: Data Delivery Fulfillment & Request Closure

**Overview**

The third phase of the archived data delivery pipeline generally involves executing the delivery, enabling the targeted lab to access the requested data cohort. This phase also invovles confirming that the requested files were successfully delivered to the lab and that the delivery meets the request requirements.

<br>

**Roles**

- Arcus Data Repository Analyst
- Arcus Project Manager
- Application Development Representative
- Library Science Representative
- Principal Investigator/Study Team
- Project Owner

<br>

**Environments**

- Jira Projects:

    - [Arcus General Support (AG)](https://pm.arcus.chop.edu/projects/AG/queues/custom/68)
  - [Requests (REQ)](https://pm.arcus.chop.edu/projects/REQ/queues/custom/311)   
  - [Scientific Projects (SCIT)](https://pm.arcus.chop.edu/projects/SCIT/queues/custom/25)

- Jira Boards:

    - [Active Archived Data Deliveries Kanban Board](https://pm.arcus.chop.edu/secure/RapidBoard.jspa?rapidView=137)
   - [Archived Data Delivery (REQ) Sub-Tasks Kanban Board](https://pm.arcus.chop.edu/secure/RapidBoard.jspa?rapidView=154)

<br>

**Inputs**

- YML & DIP Files
- Refined REQ Jira Task

   - (Completed) Linked Dependency Tasks/Sub-Tasks
   - (Completed) Participant Feasibility Assessment Sub-Task (when necessary)
   - (Completed) Qualitative Metadata Analysis Sub-Task (when necessary)

<br>

**Outputs**

- (Completed) REQ Jira Task
- Lab access to data cohort
- Delivery files...

    - Data Delivery Files:
   - ADR Request File
   - YML File
   - Data DIP

<br>

**Procedure**<br>*(Approximate Timeline: 2 – 5 Working Days)*


When delivering archived **Relational** datasets...

1. The ADR analyst stages & tests non-coded copy of the deliverable dataset/s.
2. The ADR analyst encodes the targeted dataset and pushs it to the designated Arcus lab.
3. The ADR analyst updates the REQ Task noting delivery.

<br>
<br>

When delivering archived **Omics** datasets using the Omics software tool...

1. The AppDev developer uses the Omics software tool to read the YML file and retrieve the targeted dataset/s
2. The AppDev developer inspects, configures, and runs a de-identification pipeline (in the Arcus Lab development instance) over the retrieved dataset/s.
3. The AppDev developer uploads the de-identified dataset to the lab's designated cloud platform bucket for the delivery.
4. The AppDev developer generates a file manifest (CSV) & places it in the Arcus Lab.
5. The AppDev developer updates the REQ Task noting delivery.

<br>
<br>

When delivering archived **Omics** datasets that need manual configuration...

1. The AppDev developer applies required manual configuration to produce the targeted dataset/s.
2. The AppDev developer inspects, configures, and runs a de-identification pipeline (in the Arcus Lab development instance) over the retrieved dataset/s.
3. The AppDev developer uploads the de-identified dataset to the lab's designated cloud platform bucket for the delivery.
4. The AppDev developer generates a file manifest (CSV) & places it in the Arcus Lab.
5. The AppDev developer updates the REQ Task noting delivery.

<br>

The responsibility of confirming delivery with the PI/Study team & closing the REQ Task will depend on the input channel for the request...

- **SCIT Lab Deployment:** The PO conducts orientation with the PI/Study Team & provides confirmation of successful delivery on the REQ Task.
- **AG Request:** The Omics Sciences representative and/or ADR analyst provides confirmation of successful delivery on the REQ Task.

<br>
<br>

**Phase 3 Notes:**

- During de-identification, new identifier encoding is implemented in each lab for privacy reasons.
- The de-identification & encoding require less processing time when repurposing existing datset configurations, and should be utilized when possible.
- If a cloud bucket is for whatever reason not feasible for delivery, the developer may be opt to deliver the files directly in the lab. Avoid this when possible.
- PI approval is focused on identifying that all generalized components of the overall defined cohort appear accessible in the lab.


### Pipeline Diagram

The pipeline diagram below depicts a high-level overview of the archived data delivery process from start to finish. It is intended to convey the steps, roles, and key outputs involved in a particular phase of delivery.

In the first column, the diagram highlights at the identification of archived data requirements. Each additional column represents the next sequential stages of the process. Relevant data modality differences are broken into their own pipeline paths for clarity (ex: Archived Omics Delivery Fulfillment V.S. Archived ADR Delivery Fulfillment).

<br>

![Archived Data Delivery Pipeline](archived_data_delivery_pipeline_diagram.png)

### Workflow Diagram

The archived data delivery procedure follows a decision-based workflow, and is supplemented by its components including roles, inputs/outputs, decisions, and environments. The workflow diagram is designed to illustration the prtocess at a task and decision level. The diagram is seperated into 3 swim-lanes, each describing a phase of delivery. A few helpful tips for reading the workflow diagram...

- The square nodes in the diagram represent actions, tasks, and/or actors, and should be traversed using the arrow indicators notated.
- Triangle nodes represent decisions impacting the next appropriate step in the delivery process.
- Yellow nodes denaote a key environment involved in the process (ex: Jira).
- Parallel nodes indicate processes occurroing simultaneously, as needed by the scientific project.

<br>

![Archived Data Delivery Workflow Diagram](archived_data_delivery_workflow_diagram.png)

## Conclusion

Congratulations; you have now completed the Archived Data Delivery training course!

Please continue to the Knowledge Check, Attestation, & Feedback sections of this course before navigating away from this page!

<br>

- The knowledge check section provides a practice space for testing the information reviewed in this course.
- The attestation section contains a form which can be used to attest to completion of this course. Use the Teams survey provided to attest and obtain a receipt of course completion.
- The feedback section contains a survey which the APM team uses to iteratively improve the quality of our training. Please take a moment to complete the feedback survey; all responses are anonymous!

<br>

On behalf of the APM team, we hope this course was helpful for learning more about the process for accessing research data stored in the Arcus archvies.

### Knowledge Check

Test your knowledge on the Archived Data Delivery process taking the below quiz.

Responses are only recorded for improving the quality of the training material; there is no grading or point requirements for successful completion of this course. Take quiz as many times as you feel would be beneficial for you.

<br/>
<iframe width="640px" height="550px" src="https://forms.office.com/Pages/ResponsePage.aspx?id=FiQRprAHpUGbsdFGtXXJdZk76sp1AUtCuj5UbG5eYcxUQlBCTVJGTFBXOVgzNkRNRUZYMzVSODdRUCQlQCN0PWcu&embed=true" frameborder="0" marginwidth="0" marginheight="0" style="border: none; max-width:100%; max-height:100vh" allowfullscreen webkitallowfullscreen mozallowfullscreen msallowfullscreen> </iframe> 

### Attestation

TODO: CHANGE FORM!!

<iframe width="640px" height="550px" src="https://forms.office.com/Pages/ResponsePage.aspx?id=FiQRprAHpUGbsdFGtXXJdZk76sp1AUtCuj5UbG5eYcxUOVE2RzVHTjBNWUpYNzZJMVM1MkpORVRTUiQlQCN0PWcu&embed=true" frameborder="0" marginwidth="0" marginheight="0" style="border: none; max-width:100%; max-height:100vh" allowfullscreen webkitallowfullscreen mozallowfullscreen msallowfullscreen> </iframe>


### Course Feedback

TODO: CHANGE FORM!!

<iframe width="640px" height="550px" src="https://forms.office.com/Pages/ResponsePage.aspx?id=FiQRprAHpUGbsdFGtXXJdZk76sp1AUtCuj5UbG5eYcxUMEI0OU9HNUFPNElXSFJZVDZKUFBIUjNTUiQlQCN0PWcu&embed=true" frameborder="0" marginwidth="0" marginheight="0" style="border: none; max-width:100%; max-height:100vh" allowfullscreen webkitallowfullscreen mozallowfullscreen msallowfullscreen> </iframe>

